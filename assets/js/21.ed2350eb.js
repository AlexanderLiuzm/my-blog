(window.webpackJsonp=window.webpackJsonp||[]).push([[21],{249:function(t,a,s){"use strict";s.r(a);var e=s(0),n=Object(e.a)({},(function(){var t=this,a=t.$createElement,s=t._self._c||a;return s("ContentSlotsDistributor",{attrs:{"slot-key":t.$parent.slotKey}},[s("h1",{attrs:{id:"复杂html解析"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#复杂html解析"}},[t._v("#")]),t._v(" 复杂HTML解析")]),t._v(" "),s("h2",{attrs:{id:"写在最开头——避免直接写代码"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#写在最开头——避免直接写代码"}},[t._v("#")]),t._v(" 写在最开头——避免直接写代码")]),t._v(" "),s("p",[t._v("遇到一个复杂的HTML文档，第一个要想的不是如何赶紧写出代码把数据抓下来，而是要想有没有其他的替代方法。因为复杂的HTML如果不假思索的写下爬虫代码，很容易遇到问题。")]),t._v(" "),s("h3",{attrs:{id:"问题"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#问题"}},[t._v("#")]),t._v(" 问题")]),t._v(" "),s("p",[t._v("主要有两个问题：")]),t._v(" "),s("ol",[s("li",[t._v("代码复杂难写，不优美")]),t._v(" "),s("li",[t._v("网站更改后篇爬虫极容易失效")])]),t._v(" "),s("h3",{attrs:{id:"替代方法"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#替代方法"}},[t._v("#")]),t._v(" 替代方法")]),t._v(" "),s("p",[t._v("替代方法也是有的，最好是先看看有没有其他更好的办法，最好实在很不幸，没有其他替代方法了，再思索如何写代码。")]),t._v(" "),s("h4",{attrs:{id:"寻找“打印此页”按钮"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#寻找“打印此页”按钮"}},[t._v("#")]),t._v(" 寻找“打印此页”按钮")]),t._v(" "),s("p",[t._v("“打印此页”或者网站的移动版排版可能会比原网站更友好，可以尝试找一下，有时候会带来很大的便利。")]),t._v(" "),s("h4",{attrs:{id:"寻找隐藏在js文件里的信息"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#寻找隐藏在js文件里的信息"}},[t._v("#")]),t._v(" 寻找隐藏在Js文件里的信息")]),t._v(" "),s("p",[t._v("有的数据可能隐藏在网站加载的Js文档中。")]),t._v(" "),s("h4",{attrs:{id:"网页的url链接"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#网页的url链接"}},[t._v("#")]),t._v(" 网页的URL链接")]),t._v(" "),s("p",[t._v("网页的标题很可能在网页的URL链接中也会出现，这时就不用大费周章了，直接拿URL用不就好了？")]),t._v(" "),s("h4",{attrs:{id:"找找其他数据源"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#找找其他数据源"}},[t._v("#")]),t._v(" 找找其他数据源")]),t._v(" "),s("p",[t._v("找找看，有没有其他网站也显示了相同的数据？别的网站HTML文档是不是更容易解析与抓取？")]),t._v(" "),s("h2",{attrs:{id:"beautifulsoup"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#beautifulsoup"}},[t._v("#")]),t._v(" BeautifulSoup")]),t._v(" "),s("h3",{attrs:{id:"find-findall"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#find-findall"}},[t._v("#")]),t._v(" find() & findAll()")]),t._v(" "),s("p",[s("code",[t._v("find()")]),t._v("和"),s("code",[t._v("findAll()")]),t._v("（"),s("strong",[t._v("注意A是大写的")]),t._v("，不大写会出错）是两个最常用的函数，来看看这两个函数的定义吧。")]),t._v(" "),s("ul",[s("li",[s("code",[t._v("findAll(tag, attributes, recursive, text, limit, keywords)")])]),t._v(" "),s("li",[s("code",[t._v("find(tag, attributes, recursive, text, keywords)")])])]),t._v(" "),s("h4",{attrs:{id:"tag"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#tag"}},[t._v("#")]),t._v(" tag")]),t._v(" "),s("p",[t._v("可以传一个标签名称或者多个标签名称组成的列表作为参数。\n"),s("code",[t._v('"h1"')]),t._v(" "),s("code",[t._v('{"h1","h2","h3"}')])]),t._v(" "),s("h4",{attrs:{id:"attributes"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#attributes"}},[t._v("#")]),t._v(" attributes")]),t._v(" "),s("p",[t._v("借用书上的话说，")]),t._v(" "),s("blockquote",[s("p",[t._v("属性参数attributes是一个；用Python字典封装一个标签的若干属性和对应的属性值。")])]),t._v(" "),s("p",[t._v("示例：\n下面的代码会返回HTML文档里红色与绿色的span标签")]),t._v(" "),s("div",{staticClass:"language-python extra-class"},[s("pre",{pre:!0,attrs:{class:"language-python"}},[s("code",[t._v("bsObj"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("findAll"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"span"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"class"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"green"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"red"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),s("p",[t._v("调用属性来抓取标签要把属性写成字典的样子。用属性的名称作为Key，用属性的值作为Value，要用到多个不同的属性，他们之间用逗号隔开就可以了。")]),t._v(" "),s("h4",{attrs:{id:"recursive"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#recursive"}},[t._v("#")]),t._v(" recursive")]),t._v(" "),s("p",[t._v("recursive参数主要是设定BeautifulSoup是否查找我们找寻的标签的所有子标签。设置为True，那就查找所有子标签，如果是False，那就只查找文档的一级标签。recursive参数的默认值为True。")]),t._v(" "),s("h4",{attrs:{id:"text"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#text"}},[t._v("#")]),t._v(" text")]),t._v(" "),s("p",[t._v("text参数是用标签的文本内容去匹配，而不是标签的属性。")]),t._v(" "),s("h4",{attrs:{id:"limit"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#limit"}},[t._v("#")]),t._v(" limit")]),t._v(" "),s("p",[t._v("limit参数只有findAll()函数才有，这个参数可以指定查找前x个我们想要找的标签。find()函数相当于指定limit=1的findAll()函数，只返回查找的第一个标签。")]),t._v(" "),s("h4",{attrs:{id:"keywords"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#keywords"}},[t._v("#")]),t._v(" keywords")]),t._v(" "),s("p",[t._v("keywords参数可以让我们选择具有特定属性的标签。示例："),s("code",[t._v('allText = bsObj.findAll(id="text")')]),t._v("。虽然说看起来好像很方便，但是其实keywords能做到的，通过Tag+Attrubute也能实现。并且使用keywords是有限制的，例如"),s("code",[t._v("class")]),t._v("是Python的保留字段，也就是说我们使用keywords参数时是无法查找"),s("code",[t._v("class")]),t._v("属性对应的标签的。解决的办法是这样写"),s("code",[t._v('bsObj.findAll(class_="green")')]),t._v("。")]),t._v(" "),s("p",[t._v("那这是否说明我们可以放弃keywords参数，全面转向Tag+Attribute就可以了呢？其实也不尽然，keywords属性也有他的独到的用武之地。")]),t._v(" "),s("blockquote",[s("p",[t._v("通过标签参数tag把标签列表传到"),s("code",[t._v(".findAll()")]),t._v("里获取一列标签，其实就是一个“或”关系的过滤器。如果你的标签列表很长，就需要花很长时间才能完成。而关键词keywords可以让你增加一个“与”关系的过滤器来简化工作。")])]),t._v(" "),s("h3",{attrs:{id:"通过属性抓取到标签后"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#通过属性抓取到标签后"}},[t._v("#")]),t._v(" 通过属性抓取到标签后")]),t._v(" "),s("p",[t._v("上面讲到的"),s("code",[t._v("find()")]),t._v("和"),s("code",[t._v("findAll()")]),t._v("函数可以帮助我们通过标签、属性甚至标签内的文本去匹配某些标签，匹配到特定的标签之后我们还想要提取出其中包含的信息，那就要用到下面的两个函数了。")]),t._v(" "),s("h4",{attrs:{id:"获取标签内的文本get-text"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#获取标签内的文本get-text"}},[t._v("#")]),t._v(" 获取标签内的文本"),s("code",[t._v("get_text( )")])]),t._v(" "),s("blockquote",[s("p",[s("code",[t._v("get_text()")]),t._v("会把你正在处理的HTML文档中所有的标签都清除，然后返回一个只包含文字的字符串。")])]),t._v(" "),s("p",[t._v("就是说，用了这个函数，我们可以提取出html标签之间包含的内容。一般情况下，我们会最后再用这个函数，因为我们总是希望可以尽量的保留HTML文档的标签结构。")]),t._v(" "),s("h4",{attrs:{id:"获取标签的属性-src"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#获取标签的属性-src"}},[t._v("#")]),t._v(" 获取标签的属性"),s("code",[t._v('["src"]')])]),t._v(" "),s("blockquote",[s("p",[t._v("在网络数据采集的时候，你往往不需要查找标签的内容，而是需要查找标签属性。比如标签"),s("code",[t._v("<a>")]),t._v("只想的URL连接包含在"),s("code",[t._v("herf")]),t._v("属性当中，或者"),s("code",[t._v("<img>")]),t._v("标签的图片文件包含在"),s("code",[t._v("src")]),t._v("属性中，这时获取标签属性就变得非常有用了。")])]),t._v(" "),s("p",[t._v("如果我们不对匹配到的内容做任何处理，那么返回给我们的就是一个Python字典对象，而我们想要提取出特定属性的属性值，我们只要给它一个Key让他去提取就可以了。")]),t._v(" "),s("p",[t._v("示例："),s("code",[t._v('myImgTag.attr["src"]')])]),t._v(" "),s("h3",{attrs:{id:"beautifulsoup库里的对象"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#beautifulsoup库里的对象"}},[t._v("#")]),t._v(" BeautifulSoup库里的对象")]),t._v(" "),s("p",[t._v("BeautifulSoup库中有四类对象，最常用的是前两种。")]),t._v(" "),s("h4",{attrs:{id:"beautifulsoup对象"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#beautifulsoup对象"}},[t._v("#")]),t._v(" BeautifulSoup对象")]),t._v(" "),s("p",[t._v("最常用的对象")]),t._v(" "),s("h4",{attrs:{id:"tag对象"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#tag对象"}},[t._v("#")]),t._v(" Tag对象")]),t._v(" "),s("p",[t._v("BeautifulSoup对象通过find和findAll，或者直接调用子标签获取的一列对象或一个对象。")]),t._v(" "),s("h4",{attrs:{id:"navigablestring对象"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#navigablestring对象"}},[t._v("#")]),t._v(" NavigableString对象")]),t._v(" "),s("p",[t._v("用来表示标签里的文字，不是标签。")]),t._v(" "),s("h4",{attrs:{id:"comment对象"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#comment对象"}},[t._v("#")]),t._v(" Comment对象")]),t._v(" "),s("p",[t._v("用来查找HTML中的注释标签")]),t._v(" "),s("h3",{attrs:{id:"导航树"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#导航树"}},[t._v("#")]),t._v(" 导航树")]),t._v(" "),s("p",[t._v("用"),s("code",[t._v("find()")]),t._v("和"),s("code",[t._v("findAll()")]),t._v("可以通过标签和属性来获取标签，而导航树则给我们提供了另外一种方法——通过位置来获取标签。")]),t._v(" "),s("h4",{attrs:{id:"子标签与后代标签"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#子标签与后代标签"}},[t._v("#")]),t._v(" 子标签与后代标签")]),t._v(" "),s("p",[t._v("子标签(Children)和后代标签(descendants)是不一样的，子标签是父标签下的一级标签，而后代标签是指父标签下的所有标签。")]),t._v(" "),s("p",[t._v("BeautifulSoup默认查找是在一个父标签的后代标签中查找我们要找的标签。比如说，"),s("code",[t._v("bsObj.div.h1")]),t._v("，BeautifulSoup会先在HTML文档中找到第一个div标签，在div标签的后代标签中查找第一个h1标签，而不会再跳出这个div向后继续查找。")]),t._v(" "),s("p",[t._v("示例：")]),t._v(" "),s("div",{staticClass:"language-python extra-class"},[s("pre",{pre:!0,attrs:{class:"language-python"}},[s("code",[s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" urllib"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("request "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" urlopen\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" bs4 "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" BeautifulSoup\nhtml "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" urlopen"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"http://www.pythonscraping.com/pages/page3.html"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nbsObj "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" BeautifulSoup"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("html"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("for")]),t._v(" child "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("in")]),t._v(" bsObj"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("find"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"table"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"id"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"giftList"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("children"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n\t"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("print")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("child"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),s("h4",{attrs:{id:"兄弟标签"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#兄弟标签"}},[t._v("#")]),t._v(" 兄弟标签")]),t._v(" "),s("p",[t._v("兄弟标签(sibling)顾名思义就是获取某个标签同一级的标签。sibling函数有四个：")]),t._v(" "),s("ol",[s("li",[t._v("获取一组标签")])]),t._v(" "),s("ul",[s("li",[t._v("next_siblings()")]),t._v(" "),s("li",[t._v("previous_siblings()")])]),t._v(" "),s("ol",{attrs:{start:"2"}},[s("li",[t._v("获取一个标签")])]),t._v(" "),s("ul",[s("li",[t._v("next_sibling")]),t._v(" "),s("li",[t._v("previous_sibling")])]),t._v(" "),s("p",[t._v("用兄弟标签的时候要注意，我们作为定位的标签不会被获取。这也很容易理解，因为一个人不能被称为是自己的兄弟嘛。哪有人说自己的兄弟是自己的？对标签来说也是一样。")]),t._v(" "),s("p",[t._v("示例：")]),t._v(" "),s("div",{staticClass:"language-python extra-class"},[s("pre",{pre:!0,attrs:{class:"language-python"}},[s("code",[s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" urllib"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("request "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" urlopen\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" bs4 "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" BeautifulSoup\n\nhtml "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" urlopen"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"http://www.pythonscraping.com/pages/page3.html"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nbsObj "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" BeautifulSoup"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("html"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("for")]),t._v(" sibling "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("in")]),t._v(" bsObj"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("find"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"table"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"id"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"giftList"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("tr"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("next_siblings"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n\t"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("print")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("sibling"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),s("h4",{attrs:{id:"父标签"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#父标签"}},[t._v("#")]),t._v(" 父标签")]),t._v(" "),s("p",[t._v("父标签(parent)在爬虫中使用的较少，因为正常的思维就是从上到下，因为父标签一般来说更少，更容易查找。但是某些特殊情况下我们也要使用父标签，比如父标签没有什么属性可以定位，而子标签却有。另外导航树的三种标签也是可以叠加使用的，使查找标签更准确。")]),t._v(" "),s("p",[t._v("示例：")]),t._v(" "),s("div",{staticClass:"language-python extra-class"},[s("pre",{pre:!0,attrs:{class:"language-python"}},[s("code",[s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" urllib"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("request "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" urlopen\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" bs4 "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" BeautifulSoup\n\nhtml "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" urlopen"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"http://pythonscraping.com/pages/page3.html"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nbsObj "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" BeautifulSoup"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("html"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("print")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("bsObj"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("find"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"img"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"src"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"../img/gifts/img1.jpg"')]),t._v("\n\t                   "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("parent"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("previous_sibling"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("get_text"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),s("h2",{attrs:{id:"正则表达式"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#正则表达式"}},[t._v("#")]),t._v(" 正则表达式")]),t._v(" "),s("p",[t._v("正则表达式可以识别正则字符串，正则表达式相当于定下了一个规则，"),s("strong",[t._v("如果一串字符符合这个规则，就返回这串字符，而如果不符合，就不返回，直接忽略他")]),t._v("。")]),t._v(" "),s("h3",{attrs:{id:"正则表达式常用符号"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#正则表达式常用符号"}},[t._v("#")]),t._v(" 正则表达式常用符号")]),t._v(" "),s("table",[s("thead",[s("tr",[s("th",{staticStyle:{"text-align":"center"}},[t._v("符号")]),t._v(" "),s("th",{staticStyle:{"text-align":"center"}},[t._v("含义")]),t._v(" "),s("th",{staticStyle:{"text-align":"center"}},[t._v("例子")]),t._v(" "),s("th",{staticStyle:{"text-align":"center"}},[t._v("匹配结果")])])]),t._v(" "),s("tbody",[s("tr",[s("td",{staticStyle:{"text-align":"center"}},[t._v("*")]),t._v(" "),s("td",{staticStyle:{"text-align":"center"}},[t._v("匹配前面的字符、子表达式或括号里的字符0次或多次")]),t._v(" "),s("td",{staticStyle:{"text-align":"center"}},[t._v("a*b*")]),t._v(" "),s("td",{staticStyle:{"text-align":"center"}},[t._v("aaaa,aaabbb,bbbb")])]),t._v(" "),s("tr",[s("td",{staticStyle:{"text-align":"center"}},[t._v("+")]),t._v(" "),s("td",{staticStyle:{"text-align":"center"}},[t._v("匹配前面的字符、子表达式或括号里的字符至少1次")]),t._v(" "),s("td",{staticStyle:{"text-align":"center"}},[t._v("a+b+")]),t._v(" "),s("td",{staticStyle:{"text-align":"center"}},[t._v("aaab,aabb,abbb")])]),t._v(" "),s("tr",[s("td",{staticStyle:{"text-align":"center"}},[t._v("[]")]),t._v(" "),s("td",{staticStyle:{"text-align":"center"}},[t._v("匹配任意一个字符")]),t._v(" "),s("td",{staticStyle:{"text-align":"center"}},[t._v("[A-Z]*")]),t._v(" "),s("td",{staticStyle:{"text-align":"center"}},[t._v("APPLE,CAPTAL")])]),t._v(" "),s("tr",[s("td",{staticStyle:{"text-align":"center"}},[t._v("()")]),t._v(" "),s("td",{staticStyle:{"text-align":"center"}},[t._v("表达式编组")]),t._v(" "),s("td",{staticStyle:{"text-align":"center"}},[t._v("(a*b)*")]),t._v(" "),s("td",{staticStyle:{"text-align":"center"}},[t._v("ababaaab,abaaab")])]),t._v(" "),s("tr",[s("td",{staticStyle:{"text-align":"center"}},[t._v("{m,n}")]),t._v(" "),s("td",{staticStyle:{"text-align":"center"}},[t._v("匹配前面的字符、子表达式或括号里的字符m到n次")]),t._v(" "),s("td",{staticStyle:{"text-align":"center"}},[t._v("a{2,3}b{2,3}")]),t._v(" "),s("td",{staticStyle:{"text-align":"center"}},[t._v("aabbb,aaabb")])]),t._v(" "),s("tr",[s("td",{staticStyle:{"text-align":"center"}},[t._v("[^]")]),t._v(" "),s("td",{staticStyle:{"text-align":"center"}},[t._v("匹配任意一个不再中括号里的字符")]),t._v(" "),s("td",{staticStyle:{"text-align":"center"}},[t._v("[^A-Z]*")]),t._v(" "),s("td",{staticStyle:{"text-align":"center"}},[t._v("apple,ball")])]),t._v(" "),s("tr",[s("td",{staticStyle:{"text-align":"center"}},[t._v("丨")]),t._v(" "),s("td",{staticStyle:{"text-align":"center"}},[t._v("匹配任意一个由竖线分割的字符、子表达式")]),t._v(" "),s("td",{staticStyle:{"text-align":"center"}},[t._v("b(a丨i丨e)d")]),t._v(" "),s("td",{staticStyle:{"text-align":"center"}},[t._v("bad,bid,bed")])]),t._v(" "),s("tr",[s("td",{staticStyle:{"text-align":"center"}},[t._v(".")]),t._v(" "),s("td",{staticStyle:{"text-align":"center"}},[t._v("匹配任意单个字符")]),t._v(" "),s("td",{staticStyle:{"text-align":"center"}},[t._v("b.d")]),t._v(" "),s("td",{staticStyle:{"text-align":"center"}},[t._v("bad,b$d,b d")])]),t._v(" "),s("tr",[s("td",{staticStyle:{"text-align":"center"}},[t._v("^")]),t._v(" "),s("td",{staticStyle:{"text-align":"center"}},[t._v("指定字符串开始位置的字符或子表达式")]),t._v(" "),s("td",{staticStyle:{"text-align":"center"}},[t._v("^a")]),t._v(" "),s("td",{staticStyle:{"text-align":"center"}},[t._v("apple,adin")])]),t._v(" "),s("tr",[s("td",{staticStyle:{"text-align":"center"}},[t._v("\\")]),t._v(" "),s("td",{staticStyle:{"text-align":"center"}},[t._v("转义字符")]),t._v(" "),s("td",{staticStyle:{"text-align":"center"}},[t._v("\\.\\丨\\\\")]),t._v(" "),s("td",{staticStyle:{"text-align":"center"}},[t._v(".丨\\")])]),t._v(" "),s("tr",[s("td",{staticStyle:{"text-align":"center"}},[t._v("$")]),t._v(" "),s("td",{staticStyle:{"text-align":"center"}},[t._v("用在正则表达式末尾，表示末端匹配，如果不用的话，正则表达式默认结尾会匹配.*")]),t._v(" "),s("td",{staticStyle:{"text-align":"center"}},[t._v("[A-Z]*[a-z]*$")]),t._v(" "),s("td",{staticStyle:{"text-align":"center"}},[t._v("ABCabc,azbd")])])])]),t._v(" "),s("h3",{attrs:{id:"在beautifulsoup中应用正则表达式"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#在beautifulsoup中应用正则表达式"}},[t._v("#")]),t._v(" 在BeautifulSoup中应用正则表达式")]),t._v(" "),s("p",[t._v("在BeautifulSoup中想要用正则表达式去匹配标签，要先import re这个库，然后使用"),s("code",[t._v("re.compile()")]),t._v("这个函数。")]),t._v(" "),s("p",[t._v("示例：")]),t._v(" "),s("div",{staticClass:"language-python extra-class"},[s("pre",{pre:!0,attrs:{class:"language-python"}},[s("code",[s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" urllib"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("request "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" urlopen\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" bs4 "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" BeautifulSoup\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" re\n\nhtml "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" urlopen"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"http://pythonscraping.com/pages/page3.html"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nbsObj "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" BeautifulSoup"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("html"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nimages "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" bsObj"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("findAll"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"img"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"src"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("re"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("compile")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"\\.\\.\\/img\\/gifts\\/img.*\\.jpg"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("for")]),t._v(" image "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("in")]),t._v(" images"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n\t"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("print")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("image"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"src"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),s("h2",{attrs:{id:"其他html解析库"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#其他html解析库"}},[t._v("#")]),t._v(" 其他HTML解析库")]),t._v(" "),s("p",[t._v("除了BeautifulSoup，Python还有很多别的HTML解析库，当然了，BeautifulSoup是最受欢迎的几个解析库之一。")]),t._v(" "),s("h3",{attrs:{id:"lxml"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#lxml"}},[t._v("#")]),t._v(" lxml")]),t._v(" "),s("blockquote",[s("p",[t._v("这个库可以用来解析HTML和XML文档，虽然学习它要花一些时间，但是它在处理绝大多数HTML文档时速度都非常快。")])]),t._v(" "),s("h3",{attrs:{id:"html-parser"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#html-parser"}},[t._v("#")]),t._v(" HTML parser")]),t._v(" "),s("blockquote",[s("p",[t._v("这是Python自带的解析库。（"),s("a",{attrs:{href:"https://docs.python.org/3/library/html.parser.html",target:"_blank",rel:"noopener noreferrer"}},[t._v("这是它的说明文档"),s("OutboundLink")],1),t._v("）因为不用安装，所以可以很方便的使用。")])])])}),[],!1,null,null,null);a.default=n.exports}}]);